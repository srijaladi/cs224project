{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0e8910d-b302-41a6-ae8d-2b36cdcc0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import openai\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "import transformers\n",
    "from transformers import GPT2Config, GPT2Model\n",
    "import random\n",
    "import bisect\n",
    "from bisect import bisect_left, bisect_right\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b24a14-d998-4087-b6b2-0f97cbc91d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': [{'average_generated_prob': 0,\n",
       "   'completely_generated_prob': 0.11111111111111108,\n",
       "   'overall_burstiness': 0,\n",
       "   'paragraphs': [{'completely_generated_prob': 0.11111111111111108,\n",
       "     'num_sentences': 1,\n",
       "     'start_sentence_index': 0}],\n",
       "   'sentences': [{'generated_prob': 0,\n",
       "     'perplexity': 92,\n",
       "     'sentence': 'I am running to the gym.'}]}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPTZERO_API_URL = \"https://api.gptzero.me/v2/predict/text\"\n",
    "todo = {\"document\": \"I am running to the gym.\"}\n",
    "response = requests.post(GPTZERO_API_URL, json=todo)\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3824db4-f904-4b78-a930-988c926d3309",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"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\"\n",
    "openai.api_key = API_KEY\n",
    "MODEL_ENGINE = \"text-davinci-003\"\n",
    "FOLDER_PATH = \"data/\"\n",
    "KEYS_PATH = \"keys.txt\"\n",
    "\n",
    "MODEL_NAME = 'gpt2-large'\n",
    "Cls = transformers.AutoModelForCausalLM\n",
    "\n",
    "BASE_MODEL = Cls.from_pretrained(MODEL_NAME)\n",
    "if isinstance(BASE_MODEL, transformers.GPT2LMHeadModel):\n",
    "    BASE_MODEL.transformer.gradient_checkpointing_enable()\n",
    "BASE_TOKENIZER = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if BASE_TOKENIZER.pad_token_id is None:\n",
    "    if Cls == transformers.AutoModelForCausalLM:\n",
    "        BASE_TOKENIZER.pad_token = BASE_TOKENIZER.eos_token\n",
    "    else:\n",
    "        print(\"Adding pad token to tokenizer\")\n",
    "        BASE_TOKENIZER.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        BASE_TOKENIZER.pad_token = '[PAD]'\n",
    "        \n",
    "FT_MODEL = Cls.from_pretrained(MODEL_NAME)\n",
    "if isinstance(FT_MODEL, transformers.GPT2LMHeadModel):\n",
    "    FT_MODEL.transformer.gradient_checkpointing_enable()\n",
    "FT_TOKENIZER = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "if FT_TOKENIZER.pad_token_id is None:\n",
    "    if Cls == transformers.AutoModelForCausalLM:\n",
    "        FT_TOKENIZER.pad_token = FT_TOKENIZER.eos_token\n",
    "    else:\n",
    "        print(\"Adding pad token to tokenizer\")\n",
    "        FT_TOKENIZER.add_special_tokens({'pad_token': '[PAD]'})\n",
    "        FT_TOKENIZER.pad_token = '[PAD]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c90783d-78cc-4ac0-aa43-2240d03f3c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sentence_coherence(sentence):\n",
    "    modified_prompt = \"\"\"answer in one word yes or no: does this make sense as a sentence \\\"\"\"\" + sentence + \"\"\"\\\"\"\"\"\n",
    "    print(modified_prompt)\n",
    "    # Generate a response\n",
    "    completion = openai.Completion.create(\n",
    "        engine=MODEL_ENGINE,\n",
    "        prompt=modified_prompt,\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    \n",
    "    res = completion.choices[0].text.strip()\n",
    "    print(res)\n",
    "    if res.lower()[:2] == \"no\":\n",
    "        return \"Incoherent\"\n",
    "    elif res.lower()[:3] == \"yes\":\n",
    "        return \"Coherent\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def sentence_embedding(input_sentence, return_type = \"torch\"):\n",
    "    response = openai.Embedding.create(\n",
    "    input=input_sentence,\n",
    "    engine=\"text-similarity-davinci-001\")\n",
    "    res = response.data[0]['embedding']\n",
    "    \n",
    "    if return_type.lower() == \"np\" or return_type.lower() == \"numpy\":\n",
    "        return np.array(res)\n",
    "    elif return_type.lower() == \"list\":\n",
    "        return res\n",
    "    else:\n",
    "        return torch.tensor(res)\n",
    "    \n",
    "def similarity_score_single(sentence1, sentence2):\n",
    "    embed1 = sentence_embedding(sentence1, \"torch\")\n",
    "    embed2 = sentence_embedding(sentence2, \"torch\")\n",
    "    norm1 = torch.sqrt(torch.sum(embed1 * embed1))\n",
    "    norm2 = torch.sqrt(torch.sum(embed2 * embed2))\n",
    "    numerator = torch.dot(embed1, embed2)\n",
    "    denominator = norm1 * norm2\n",
    "    return numerator/denominator\n",
    "\n",
    "def sentence_coherence_score_single(input_sentence):\n",
    "    modified_prompt = \"Evaluate the coherence score of this sentence as a value between 0 and 1:\\n\\n\" + input_sentence\n",
    "    response = openai.Completion.create(\n",
    "      model=MODEL_ENGINE,\n",
    "      prompt=modified_prompt,\n",
    "      temperature=0,\n",
    "      max_tokens=60,\n",
    "      top_p=1.0,\n",
    "      frequency_penalty=0.0,\n",
    "      presence_penalty=0.0\n",
    "    )\n",
    "    res = response.choices[0]['text'].strip()\n",
    "    return float(res)\n",
    "\n",
    "def compute_sentences(responses):\n",
    "    essays = [i.split(\"\\n\") for i in responses]\n",
    "    sentences = []\n",
    "    for essay_li in essays:\n",
    "        essay_sents = []\n",
    "        for portion in essay_li:\n",
    "            if len(portion.strip()) == 0:\n",
    "                continue\n",
    "            add_li = re.split('(?<=[.!?]) +',str(portion))\n",
    "            essay_sents += add_li\n",
    "            #print(essay_sents)\n",
    "        sentences.append(essay_sents)\n",
    "    return sentences\n",
    "    \n",
    "def compute_sentences_single_essay(essay):\n",
    "    essay_li = essay.split(\"\\n\")\n",
    "    essay_sents = []\n",
    "    for portion in essay_li:\n",
    "        if len(portion.strip()) == 0:\n",
    "            continue\n",
    "        add_li = re.split('(?<=[.!?]) +',str(portion))\n",
    "        essay_sents += add_li\n",
    "    return essay_sents\n",
    "\n",
    "def collect_data(word):\n",
    "    num = 3\n",
    "    prompt = \"Write a long essay about \" + word\n",
    "    completion = openai.Completion.create(\n",
    "        engine=MODEL_ENGINE,\n",
    "        prompt=prompt,\n",
    "        max_tokens=3500,\n",
    "        n=num,\n",
    "        stop=None,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "        \n",
    "    responses = [completion.choices[i].text for i in range(len(completion.choices))]\n",
    "    \n",
    "    sentences_per = compute_sentences(responses)\n",
    "    lens = [len(sen) for sen in sentences_per]\n",
    "    \n",
    "    for i,essay in enumerate(responses):\n",
    "        filepath = FOLDER_PATH + word + str(i)\n",
    "        f = open(filepath, \"w\")\n",
    "        f.write(essay)\n",
    "        f.close()\n",
    "        \n",
    "    return lens\n",
    "        \n",
    "def gen_data(num_words):\n",
    "    all_nouns = []\n",
    "    file1 = open('nounlist.txt', 'r')\n",
    "    lines = file1.readlines()\n",
    "    all_nouns = [i.strip() for i in lines]\n",
    "    \n",
    "    amt_keys = np.loadtxt(KEYS_PATH)\n",
    "    prev_gen = np.sum(amt_keys)\n",
    "        \n",
    "    start_index = int(len(amt_keys)/3)\n",
    "    stop_index = min(start_index + num_words, len(all_nouns))\n",
    "    for i in range(start_index,stop_index):\n",
    "        print(i)\n",
    "        lens = collect_data(all_nouns[i])\n",
    "        \n",
    "        amt_keys = np.append(amt_keys, np.array(lens))\n",
    "        total_gen = np.sum(amt_keys)\n",
    "        \n",
    "        print(\"Generated: \" + str(lens) + \" for: \" + str(all_nouns[i]))\n",
    "        print(\"Total generated now: \" + str(total_gen) + \", Generated this iteration: \" + str(total_gen - prev_gen))\n",
    "        \n",
    "        np.savetxt(KEYS_PATH, amt_keys)\n",
    "        \n",
    "        time.sleep(60)\n",
    "        \n",
    "def get_prob(model, tokenizer, full_sentence, encoded_sentence):    \n",
    "    \n",
    "    def get_word_prob(ids_so_far, true_token):\n",
    "        with torch.inference_mode():  \n",
    "            end_model = model(input_ids = ids_so_far)\n",
    "            logits = end_model.logits\n",
    "            #print(ids_so_far)\n",
    "            #print(tokenizer.decode(ids_so_far))\n",
    "            #print(logits.size())\n",
    "            all_probs = torch.nn.functional.softmax(logits, dim = -1)\n",
    "            return all_probs[-1][true_token]\n",
    "    \n",
    "    all_probs = torch.zeros(len(encoded_sentence))\n",
    "\n",
    "    total_log_prob = 0\n",
    "    #print(all_probs)\n",
    "    for i in range(0,len(encoded_sentence)):\n",
    "        word_cond_prob = get_word_prob(encoded_sentence[:i+1], encoded_sentence[i])\n",
    "        all_probs[i] = word_cond_prob\n",
    "        total_log_prob += np.log(word_cond_prob)\n",
    "    \n",
    "    return total_log_prob, all_probs\n",
    "\n",
    "def compute_perplexity(model, tokenizer, full_sentence, encoded_sentence):\n",
    "    base_log_prob, base_each_prob = get_prob(model, tokenizer, full_sentence, encoded_sentence)\n",
    "    #print(base_log_prob)\n",
    "    N = len(encoded_sentence)\n",
    "    \n",
    "    overall_perplexity = 2 ** (-(1/N) * base_log_prob/np.log(2)) #(1/base_prob) ** (1/len(encoded_sentence))\n",
    "    return overall_perplexity, base_each_prob\n",
    "    \n",
    "def find_mask_indexes(model, tokenizer, full_sentence, encoded_sentence, num_mask = None, mask_cutoff = None):\n",
    "    sentence_perplexity, prob_each_index = compute_perplexity(model, tokenizer, full_sentence, encoded_sentence)\n",
    "\n",
    "    indexes_by_prob = [[p,i] for i,p in enumerate(prob_each_index)]\n",
    "    indexes_by_prob = sorted(indexes_by_prob)\n",
    "    \n",
    "    #print(indexes_by_prob)\n",
    "    \n",
    "    if not(num_mask is None):\n",
    "        res = [tu[1] for tu in indexes_by_prob[:num_mask]]\n",
    "    elif not(mask_cutoff is None):\n",
    "        res = []\n",
    "        for p,i in indexes_by_prob:\n",
    "            if p < mask_cutoff:\n",
    "                break\n",
    "            res.append(i)\n",
    "    else:\n",
    "        print(\"ERROR: NEED TYPE OF MASK (EITHER NUMBER OR CUTOFF)\")\n",
    "        return None\n",
    "    \n",
    "    return res\n",
    "\n",
    "def compute_loss(model, tokenizer, new_sentence, original_sentence, hyperparameters):\n",
    "    a = hyperparameters['alpha']\n",
    "    b = hyperparameters['beta']\n",
    "    d = hyperparameters['delta']\n",
    "    \n",
    "    new_encoded_sentence = tokenizer(new_sentence, return_tensors = 'pt')['input_ids'][0]\n",
    "    \n",
    "    perplexity, _ = compute_perplexity(model, tokenizer, new_sentence, new_encoded_sentence)\n",
    "    coherence = sentence_coherence_score_single(new_sentence)\n",
    "    similarity = similarity_score_single(new_sentence, original_sentence)\n",
    "    \n",
    "    objective = a * perplexity + b * coherence + d * similarity\n",
    "    loss = -objective\n",
    "    \n",
    "    return loss, perplexity, coherence, similarity\n",
    "\n",
    "def fill_masked_indexes(ft_model, ft_tokenizer, sentence, encoded_sentence, mask_indexes):\n",
    "    def get_inference(all_ids, idx):\n",
    "        with torch.inference_mode():  \n",
    "            end_model = ft_model(input_ids = all_ids)\n",
    "            logits = end_model.logits\n",
    "            res = torch.argmax(logits[idx])\n",
    "            print(res)\n",
    "            return res\n",
    "    \n",
    "    curr_encoded_sentence = torch.clone(encoded_sentence)\n",
    "    for idx in mask_indexes:\n",
    "        new_token = get_inference(curr_encoded_sentence, idx)\n",
    "        curr_encoded_sentence[idx] = new_token\n",
    "    \n",
    "    return curr_encoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7fe8c6b-bdf4-4a4f-803c-b99816b91ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2215,   314,   467, 12478,    11,   314,  4929,   257,  1256,   286,\n",
      "         5916,    13])\n",
      "[0, 8, 11]\n",
      "tensor(345)\n",
      "tensor(286)\n",
      "tensor(314)\n",
      "tensor([  345,   314,   467, 12478,    11,   314,  4929,   257,   286,   286,\n",
      "         5916,   314])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"When I go fishing, I catch a lot of fish.\"\n",
    "encoded_sentence = BASE_TOKENIZER(sentence, return_tensors = 'pt')['input_ids'][0]\n",
    "print(encoded_sentence)\n",
    "mask_indexes = find_mask_indexes(BASE_MODEL, BASE_TOKENIZER, sentence, encoded_sentence, num_mask = 3)\n",
    "print(mask_indexes)\n",
    "final_sentence_encoded = fill_masked_indexes(FT_MODEL, FT_TOKENIZER, sentence, encoded_sentence, mask_indexes)\n",
    "print(final_sentence_encoded)\n",
    "#print(FT_TOKENIZER.decode(final_sentence_encoded)) # COMPUTE CANNOT HANDLE THIS COMPUTATION -> FIX ON GPU/CREDITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ce23ec1-5c8c-470c-97cf-d315d3e1b349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We may feel that we are not able to give our loved one the attention and support they need, or that we are not able to be there for them when they need us.\n",
      "(tensor(-8.3438), tensor(19038.4082), 0.86, tensor(1.))\n",
      "The aardvark is a shy and secretive animal, and it is rarely seen in the wild.\n",
      "(tensor(-11.3194), tensor(47194.0898), 0.9, tensor(1.0000))\n",
      "The album has been praised for its production values and songwriting.\n",
      "(tensor(-9.3231), tensor(28830.9062), 0.86, tensor(1.))\n",
      "Accelerators are used to study the structure of matter and the behavior of particles, and are used to create new materials and technologies.\n",
      "(tensor(-8.4067), tensor(16866.6777), 0.93, tensor(1.))\n",
      "Over the next two centuries, the slave trade grew and enslaved Africans were brought to the United States to work as laborers on plantations and in other industries.\n",
      "(tensor(-8.5936), tensor(19936.1367), 0.9, tensor(1.))\n",
      "Accountants can also pursue higher education and become certified public accountants (CPAs).\n",
      "(tensor(-19.7300), tensor(131299.7188), 0.9, tensor(1.))\n",
      "Achieving success is something that everyone strives for in life.\n",
      "(tensor(-12.1825), tensor(57424.8750), 0.86, tensor(1.0000))\n",
      "In such places, people may not be able to understand each other if they have different accents.\n",
      "(tensor(-8.0479), tensor(20479.1465), 0.75, tensor(1.0000))\n",
      "They believe that it is cruel and unusual punishment and that it does not serve as a deterrent to crime.\n",
      "(tensor(-9.2144), tensor(26143.8301), 0.9, tensor(1.0000))\n",
      "It also means that everyone must be willing to listen to others and take their opinions into consideration when making decisions.\n",
      "(tensor(-10.0926), tensor(33725.7539), 0.93, tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "amt_keys = np.loadtxt(KEYS_PATH)\n",
    "hyperparameters = {'alpha': 0.0001, 'beta': 4, 'delta': 3}\n",
    "for i in range(10):\n",
    "    file = random.randint(0,len(amt_keys)-1)\n",
    "    sent = random.randint(0,amt_keys[file]-1)\n",
    "    \n",
    "    all_nouns = []\n",
    "    file1 = open('nounlist.txt', 'r')\n",
    "    lines = file1.readlines()\n",
    "    all_nouns = [i.strip() for i in lines]\n",
    "    \n",
    "    noun = all_nouns[file//3]\n",
    "    vers = file%3\n",
    "    \n",
    "    filepath = FOLDER_PATH + str(noun) + str(vers)\n",
    "    \n",
    "    f1 = open(filepath, 'r')\n",
    "    lines = \"\".join(f1.readlines())\n",
    "    \n",
    "    #print(lines)\n",
    "    \n",
    "    sents = compute_sentences_single_essay(lines)\n",
    "    sentence = sents[sent]\n",
    "    print(sentence)\n",
    "    print(compute_loss(BASE_MODEL, BASE_TOKENIZER, sentence, sentence, hyperparameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1174e3d-966a-4e40-b70c-aaf472ea8ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "score = sentence_coherence_score_single(\"I am going to the gym.\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec7c3f0-7dff-4f99-be10-76eda07133f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9307)\n"
     ]
    }
   ],
   "source": [
    "score = similarity_score_single(\"I am running to the gym.\", \"I am walking to the gym.\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5a41c10-a25c-43a8-858a-b4d127b3e3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "You exceeded your current quota, please check your plan and billing details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0mTraceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgen_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mgen_data\u001b[0;34m(num_words)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_index,stop_index):\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m--> 121\u001b[0m     lens \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_nouns\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     amt_keys \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(amt_keys, np\u001b[38;5;241m.\u001b[39marray(lens))\n\u001b[1;32m    124\u001b[0m     total_gen \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(amt_keys)\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mcollect_data\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m     84\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     85\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a long essay about \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m word\n\u001b[0;32m---> 86\u001b[0m completion \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODEL_ENGINE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m responses \u001b[38;5;241m=\u001b[39m [completion\u001b[38;5;241m.\u001b[39mchoices[i]\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(completion\u001b[38;5;241m.\u001b[39mchoices))]\n\u001b[1;32m     97\u001b[0m sentences_per \u001b[38;5;241m=\u001b[39m compute_sentences(responses)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    625\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    680\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
     ]
    }
   ],
   "source": [
    "gen_data(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9da24ff0-eb04-4541-a681-ac3b8b3dc634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a long essay about cars\n",
      "['\\n\\nCars are one of the most important inventions of the modern age. They have become an integral part of our lives, providing us with a convenient and comfortable way to travel. Cars have revolutionized the way we travel, allowing us to go farther and faster than ever before.\\n\\nCars are powered by an internal combustion engine, which converts fuel into energy. This energy is used to turn the wheels of the car, allowing it to move. Cars come in a variety of sizes, shapes, and types, from small compact cars to large luxury vehicles. They can be powered by gasoline, diesel, or electricity.\\n\\nCars are incredibly complex machines, with many different components and systems that work together to make them run. The engine, transmission, brakes, suspension, and steering are all important components of a car. Each of these systems must be in good condition for the car to run properly.\\n\\nCars also come with a variety of safety features, such as airbags and seat belts. These safety features can help protect drivers and passengers in the event of an accident. Cars also come with a variety of convenience features, such as power windows, power locks, and cruise control.\\n\\nOwning a car can be expensive. The cost of buying a car, as well as the cost of fuel, insurance, and maintenance can add up quickly. It is important to consider these costs when deciding whether or not to purchase a car.\\n\\nCars can also have a negative impact on the environment. The burning of fuel releases emissions into the atmosphere, which can contribute to air pollution. It is important to be aware of the environmental impact of cars and to take steps to reduce emissions when possible.\\n\\nCars are an incredibly important invention. They have revolutionized the way we travel and have made our lives easier. However, it is important to be aware of the costs and environmental impacts associated with owning a car.', \"\\n\\nCars have been a part of our lives for over a century now. They have changed the way we live, work, and travel. They have made our lives easier and more efficient. Cars have become an integral part of our society and our culture.\\n\\nCars have been around since the late 19th century, but it wasn't until the early 20th century that they began to be mass-produced and widely used. The first mass-produced car was the Ford Model T, which was released in 1908. The Model T was a huge success and sold over 15 million units in its lifetime. This was the start of the automotive revolution, and it changed the way people traveled and commuted.\\n\\nSince then, cars have become much more advanced and efficient. Automakers have developed cars that are more fuel-efficient, safer, and more reliable. This has made them much more accessible to the general public. Cars have also become much more affordable, making them more attainable for people of all income levels.\\n\\nCars have also had a huge impact on the environment. Automakers have developed more efficient engines and have started using more sustainable materials in the production of cars. This has led to a decrease in emissions and air pollution. Additionally, cars have become much more fuel-efficient, leading to a decrease in fuel consumption.\\n\\nCars have also had a huge impact on the economy. Automakers employ thousands of people and generate billions of dollars in revenue. This money is used to create jobs, fund research and development, and invest in new technologies. This has helped to create a strong and vibrant economy.\\n\\nCars have become an integral part of our lives. They have changed the way we live, work, and travel. They have made our lives easier and more efficient. They have also had a huge impact on the environment and the economy. Cars are here to stay, and they will continue to shape our lives for many years to come.\", '\\n\\nCars have been a part of everyday life for many decades now, and it’s hard to imagine a world without them. Cars are a symbol of freedom and independence, and they’ve come to represent the American Dream. But cars aren’t just a symbol of freedom, they’re also a big part of our economy and our lives.\\n\\nCars are a major part of our economy. In the United States, the automobile industry is one of the largest employers, providing jobs for millions of people. The auto industry also contributes billions of dollars to the GDP each year. Cars are also a major source of revenue for governments, as taxes and fees on cars make up a large portion of state and local budgets.\\n\\nCars are also a major part of our lives. They provide us with a way to get around, to go to work, to go shopping, to visit family and friends, and to go on vacation. Cars are also a way for us to express our own unique style and personality. We can customize our cars to fit our own preferences and tastes.\\n\\nBut cars also have a dark side. Cars produce air pollution, which can cause health problems for people, especially those with asthma or other respiratory illnesses. Cars also contribute to global warming, as they produce greenhouse gases that trap heat in the atmosphere. And, of course, cars are a major factor in traffic accidents, which can cause serious injuries and even death.\\n\\nDespite the dark side of cars, they remain an essential part of our lives. We rely on them to get around, to go to work, to visit family and friends, and to go on vacation. We customize them to fit our own preferences and tastes. We use them to express our own unique style and personality. And, of course, we use them to get to places we couldn’t otherwise get to. Cars are a major part of our economy and our lives, and they’re here to stay.']\n"
     ]
    }
   ],
   "source": [
    "# Set up the model and prompt\n",
    "model_engine = \"text-davinci-003\"\n",
    "prompt = \"\"\"Write a long essay about cars\"\"\"\n",
    "print(prompt)\n",
    "\n",
    "# Generate a response\n",
    "completion = openai.Completion.create(\n",
    "    engine=model_engine,\n",
    "    prompt=prompt,\n",
    "    max_tokens=3500,\n",
    "    n=3,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "responses = [completion.choices[i].text for i in range(len(completion.choices))]\n",
    "\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4d8c043f-e851-4a91-98c5-9c79e691274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Cars are one of the most important inventions of the modern age.', 'They have become an integral part of our lives, providing us with a convenient and comfortable way to travel.', 'Cars have revolutionized the way we travel, allowing us to go farther and faster than ever before.', 'Cars are powered by an internal combustion engine, which converts fuel into energy.', 'This energy is used to turn the wheels of the car, allowing it to move.', 'Cars come in a variety of sizes, shapes, and types, from small compact cars to large luxury vehicles.', 'They can be powered by gasoline, diesel, or electricity.', 'Cars are incredibly complex machines, with many different components and systems that work together to make them run.', 'The engine, transmission, brakes, suspension, and steering are all important components of a car.', 'Each of these systems must be in good condition for the car to run properly.', 'Cars also come with a variety of safety features, such as airbags and seat belts.', 'These safety features can help protect drivers and passengers in the event of an accident.', 'Cars also come with a variety of convenience features, such as power windows, power locks, and cruise control.', 'Owning a car can be expensive.', 'The cost of buying a car, as well as the cost of fuel, insurance, and maintenance can add up quickly.', 'It is important to consider these costs when deciding whether or not to purchase a car.', 'Cars can also have a negative impact on the environment.', 'The burning of fuel releases emissions into the atmosphere, which can contribute to air pollution.', 'It is important to be aware of the environmental impact of cars and to take steps to reduce emissions when possible.', 'Cars are an incredibly important invention.', 'They have revolutionized the way we travel and have made our lives easier.', 'However, it is important to be aware of the costs and environmental impacts associated with owning a car.'], ['Cars have been a part of our lives for over a century now.', 'They have changed the way we live, work, and travel.', 'They have made our lives easier and more efficient.', 'Cars have become an integral part of our society and our culture.', \"Cars have been around since the late 19th century, but it wasn't until the early 20th century that they began to be mass-produced and widely used.\", 'The first mass-produced car was the Ford Model T, which was released in 1908.', 'The Model T was a huge success and sold over 15 million units in its lifetime.', 'This was the start of the automotive revolution, and it changed the way people traveled and commuted.', 'Since then, cars have become much more advanced and efficient.', 'Automakers have developed cars that are more fuel-efficient, safer, and more reliable.', 'This has made them much more accessible to the general public.', 'Cars have also become much more affordable, making them more attainable for people of all income levels.', 'Cars have also had a huge impact on the environment.', 'Automakers have developed more efficient engines and have started using more sustainable materials in the production of cars.', 'This has led to a decrease in emissions and air pollution.', 'Additionally, cars have become much more fuel-efficient, leading to a decrease in fuel consumption.', 'Cars have also had a huge impact on the economy.', 'Automakers employ thousands of people and generate billions of dollars in revenue.', 'This money is used to create jobs, fund research and development, and invest in new technologies.', 'This has helped to create a strong and vibrant economy.', 'Cars have become an integral part of our lives.', 'They have changed the way we live, work, and travel.', 'They have made our lives easier and more efficient.', 'They have also had a huge impact on the environment and the economy.', 'Cars are here to stay, and they will continue to shape our lives for many years to come.'], ['Cars have been a part of everyday life for many decades now, and it’s hard to imagine a world without them.', 'Cars are a symbol of freedom and independence, and they’ve come to represent the American Dream.', 'But cars aren’t just a symbol of freedom, they’re also a big part of our economy and our lives.', 'Cars are a major part of our economy.', 'In the United States, the automobile industry is one of the largest employers, providing jobs for millions of people.', 'The auto industry also contributes billions of dollars to the GDP each year.', 'Cars are also a major source of revenue for governments, as taxes and fees on cars make up a large portion of state and local budgets.', 'Cars are also a major part of our lives.', 'They provide us with a way to get around, to go to work, to go shopping, to visit family and friends, and to go on vacation.', 'Cars are also a way for us to express our own unique style and personality.', 'We can customize our cars to fit our own preferences and tastes.', 'But cars also have a dark side.', 'Cars produce air pollution, which can cause health problems for people, especially those with asthma or other respiratory illnesses.', 'Cars also contribute to global warming, as they produce greenhouse gases that trap heat in the atmosphere.', 'And, of course, cars are a major factor in traffic accidents, which can cause serious injuries and even death.', 'Despite the dark side of cars, they remain an essential part of our lives.', 'We rely on them to get around, to go to work, to visit family and friends, and to go on vacation.', 'We customize them to fit our own preferences and tastes.', 'We use them to express our own unique style and personality.', 'And, of course, we use them to get to places we couldn’t otherwise get to.', 'Cars are a major part of our economy and our lives, and they’re here to stay.']]\n"
     ]
    }
   ],
   "source": [
    "essays = [i.split(\"\\n\") for i in responses]\n",
    "sentences = []\n",
    "for essay_li in essays:\n",
    "    essay_sents = []\n",
    "    for portion in essay_li:\n",
    "        if len(portion.strip()) == 0:\n",
    "            continue\n",
    "        add_li = re.split('(?<=[.!?]) +',str(portion))\n",
    "        essay_sents += add_li\n",
    "        #print(essay_sents)\n",
    "    sentences.append(essay_sents)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e043be-f86d-40aa-b7c0-2e9e4d4bdcda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
